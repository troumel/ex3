{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID Data Analyzer\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:05:06.577826Z",
     "iopub.status.busy": "2025-11-11T19:05:06.577826Z",
     "iopub.status.idle": "2025-11-11T19:05:07.145756Z",
     "shell.execute_reply": "2025-11-11T19:05:07.144480Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CovidDataAnalyzer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:05:07.146729Z",
     "iopub.status.busy": "2025-11-11T19:05:07.146729Z",
     "iopub.status.idle": "2025-11-11T19:05:07.166450Z",
     "shell.execute_reply": "2025-11-11T19:05:07.166450Z"
    }
   },
   "outputs": [],
   "source": [
    "class CovidDataAnalyzer:\n",
    "    \"\"\"\n",
    "    A class to analyze COVID-19 data.\n",
    "    \n",
    "    Attributes:\n",
    "        data: stores the loaded dataset\n",
    "        filtered_data: stores filtered datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initialize the CovidDataAnalyzer with data from a file.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the data file (CSV, Excel, etc.)\n",
    "        \"\"\"\n",
    "        self.filtered_data = None\n",
    "        self.data = self.load_data(file_path)\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Load data from a CSV file and return it.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the CSV file\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: The loaded dataframe, or None if an error occurred\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            print(f\"Data loaded successfully from {file_path}\")\n",
    "            print(f\"Dataset shape: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File '{file_path}' not found.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def describe_data(self):\n",
    "        \"\"\"\n",
    "        Print the shape, column names, and basic statistics of the dataset.\n",
    "        Provides insights based on the statistics.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"DATASET OVERVIEW\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Shape\n",
    "        print(f\"\\nDataset Shape: {self.data.shape}\")\n",
    "        print(f\"   - Number of rows: {self.data.shape[0]:,}\")\n",
    "        print(f\"   - Number of columns: {self.data.shape[1]}\")\n",
    "        \n",
    "        # Column names and data types\n",
    "        print(f\"\\nColumn Names and Data Types:\")\n",
    "        print(\"-\" * 80)\n",
    "        for idx, (col, dtype) in enumerate(zip(self.data.columns, self.data.dtypes), 1):\n",
    "            print(f\"   {idx}. {col:<30} ({dtype})\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"\\nBasic Statistics (Numeric Columns):\")\n",
    "        print(\"-\" * 80)\n",
    "        print(self.data.describe())\n",
    "        \n",
    "        # Missing values\n",
    "        print(f\"\\nMissing Values:\")\n",
    "        print(\"-\" * 80)\n",
    "        missing = self.data.isnull().sum()\n",
    "        missing_pct = (missing / len(self.data) * 100).round(2)\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Missing Count': missing,\n",
    "            'Percentage': missing_pct\n",
    "        })\n",
    "        print(missing_df[missing_df['Missing Count'] > 0])\n",
    "        \n",
    "        # Data types summary\n",
    "        print(f\"\\nData Types Summary:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(self.data.dtypes.value_counts())\n",
    "        \n",
    "        # First few rows\n",
    "        print(f\"\\nFirst 5 Rows:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(self.data.head())\n",
    "        \n",
    "        # Insights\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INSIGHTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        insights = []\n",
    "        \n",
    "        # Dataset size insight\n",
    "        if self.data.shape[0] > 10000:\n",
    "            insights.append(f\"Large dataset with {self.data.shape[0]:,} records - sufficient for statistical analysis\")\n",
    "        elif self.data.shape[0] > 1000:\n",
    "            insights.append(f\"Medium-sized dataset with {self.data.shape[0]:,} records\")\n",
    "        else:\n",
    "            insights.append(f\"Small dataset with {self.data.shape[0]:,} records - consider collecting more data\")\n",
    "        \n",
    "        # Missing values insight\n",
    "        total_missing = self.data.isnull().sum().sum()\n",
    "        if total_missing > 0:\n",
    "            missing_pct_total = (total_missing / (self.data.shape[0] * self.data.shape[1]) * 100).round(2)\n",
    "            insights.append(f\"Dataset has {total_missing:,} missing values ({missing_pct_total}% of all data)\")\n",
    "            insights.append(\"    -> Recommend using handle_missing_values() method to address this\")\n",
    "        else:\n",
    "            insights.append(\"No missing values detected - data is complete\")\n",
    "        \n",
    "        # Numeric columns insight\n",
    "        numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if numeric_cols:\n",
    "            insights.append(f\"{len(numeric_cols)} numeric columns available for statistical analysis\")\n",
    "        \n",
    "        # Categorical columns insight\n",
    "        categorical_cols = self.data.select_dtypes(include=['object']).columns.tolist()\n",
    "        if categorical_cols:\n",
    "            insights.append(f\"{len(categorical_cols)} categorical columns available for grouping and filtering\")\n",
    "        \n",
    "        # Print insights\n",
    "        for insight in insights:\n",
    "            print(f\"\\n{insight}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    def handle_missing_values(self):\n",
    "        \"\"\"\n",
    "        Handle missing values in the dataset:\n",
    "        - Fill missing numeric values with 0\n",
    "        - Fill missing categorical values with \"Unknown\"\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"HANDLING MISSING VALUES\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Check for missing values before\n",
    "        missing_before = self.data.isnull().sum().sum()\n",
    "        print(f\"\\nMissing values before: {missing_before:,}\")\n",
    "        \n",
    "        if missing_before == 0:\n",
    "            print(\"\\nNo missing values found. Data is already complete!\")\n",
    "            return self.data\n",
    "        \n",
    "        # Identify numeric and categorical columns\n",
    "        numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = self.data.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "        # Fill numeric columns with 0\n",
    "        if numeric_cols:\n",
    "            print(f\"\\nFilling {len(numeric_cols)} numeric columns with 0:\")\n",
    "            for col in numeric_cols:\n",
    "                missing_count = self.data[col].isnull().sum()\n",
    "                if missing_count > 0:\n",
    "                    self.data[col] = self.data[col].fillna(0)\n",
    "                    print(f\"   - {col}: filled {missing_count} missing values\")\n",
    "        \n",
    "        # Fill categorical columns with \"Unknown\"\n",
    "        if categorical_cols:\n",
    "            print(f\"\\nFilling {len(categorical_cols)} categorical columns with 'Unknown':\")\n",
    "            for col in categorical_cols:\n",
    "                missing_count = self.data[col].isnull().sum()\n",
    "                if missing_count > 0:\n",
    "                    self.data[col] = self.data[col].fillna(\"Unknown\")\n",
    "                    print(f\"   - {col}: filled {missing_count} missing values\")\n",
    "        \n",
    "        # Check for missing values after\n",
    "        missing_after = self.data.isnull().sum().sum()\n",
    "        print(f\"\\nMissing values after: {missing_after:,}\")\n",
    "        print(f\"Successfully handled {missing_before - missing_after:,} missing values!\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def filter_high_cases(self) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Filter the dataset based on multiple conditions:\n",
    "        - Confirmed cases greater than 100,000\n",
    "        - Deaths above 5,000\n",
    "        - Country is not \"Unknown\"\n",
    "        \n",
    "        Saves the filtered data to self.filtered_data\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"FILTERING HIGH CASES\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Apply filters\n",
    "        print(\"\\nApplying filters:\")\n",
    "        print(\"   - Confirmed cases > 100,000\")\n",
    "        print(\"   - Deaths > 5,000\")\n",
    "        print(\"   - Country/Region != 'Unknown'\")\n",
    "        \n",
    "        self.filtered_data = self.data[\n",
    "            (self.data['Confirmed'] > 100000) & \n",
    "            (self.data['Deaths'] > 5000) & \n",
    "            (self.data['Country/Region'] != 'Unknown')\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"   - Original dataset: {len(self.data):,} rows\")\n",
    "        print(f\"   - Filtered dataset: {len(self.filtered_data):,} rows\")\n",
    "        print(f\"   - Rows filtered out: {len(self.data) - len(self.filtered_data):,}\")\n",
    "        \n",
    "        if len(self.filtered_data) > 0:\n",
    "            print(f\"\\nFiltered data saved to self.filtered_data\")\n",
    "            print(\"\\nSummary of filtered data:\")\n",
    "            print(f\"   - Unique countries: {self.filtered_data['Country/Region'].nunique()}\")\n",
    "            print(f\"   - Total confirmed cases: {self.filtered_data['Confirmed'].sum():,}\")\n",
    "            print(f\"   - Total deaths: {self.filtered_data['Deaths'].sum():,}\")\n",
    "            print(f\"   - Average confirmed cases: {self.filtered_data['Confirmed'].mean():,.0f}\")\n",
    "            print(f\"   - Average deaths: {self.filtered_data['Deaths'].mean():,.0f}\")\n",
    "        else:\n",
    "            print(\"\\nNo records match the filter criteria.\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return self.filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Test the Data Analyzer\n\nBelow is an example of how to use the CovidDataAnalyzer class with sample output:\n\n**Expected Output:**\n- Data loading confirmation with dataset shape\n- Dataset overview with statistics and insights\n- Missing values handling report\n- Filtered data results with summary statistics\n- Preview of the first 5 filtered records",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:05:07.166450Z",
     "iopub.status.busy": "2025-11-11T19:05:07.166450Z",
     "iopub.status.idle": "2025-11-11T19:05:07.280062Z",
     "shell.execute_reply": "2025-11-11T19:05:07.280062Z"
    }
   },
   "outputs": [],
   "source": "# Example usage:\nanalyzer = CovidDataAnalyzer('covid_19_data.csv')\n\n# Describe the data\nanalyzer.describe_data()\n\n# Handle missing values\nanalyzer.handle_missing_values()\n\n# Filter high cases\nanalyzer.filter_high_cases()\nprint(analyzer.filtered_data.head())"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}