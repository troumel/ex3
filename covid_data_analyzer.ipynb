{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID Data Analyzer\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:05:06.577826Z",
     "iopub.status.busy": "2025-11-11T19:05:06.577826Z",
     "iopub.status.idle": "2025-11-11T19:05:07.145756Z",
     "shell.execute_reply": "2025-11-11T19:05:07.144480Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CovidDataAnalyzer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:05:07.146729Z",
     "iopub.status.busy": "2025-11-11T19:05:07.146729Z",
     "iopub.status.idle": "2025-11-11T19:05:07.166450Z",
     "shell.execute_reply": "2025-11-11T19:05:07.166450Z"
    }
   },
   "outputs": [],
   "source": [
    "class CovidDataAnalyzer:\n",
    "    \"\"\"\n",
    "    A class to analyze COVID-19 data.\n",
    "    \n",
    "    Attributes:\n",
    "        data: stores the loaded dataset\n",
    "        filtered_data: stores filtered datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initialize the CovidDataAnalyzer with data from a file.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the data file (CSV, Excel, etc.)\n",
    "        \"\"\"\n",
    "        self.filtered_data = None\n",
    "        self.data = self.load_data(file_path)\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Load data from a CSV file and return it.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): Path to the CSV file\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: The loaded dataframe, or None if an error occurred\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            print(f\"Data loaded successfully from {file_path}\")\n",
    "            print(f\"Dataset shape: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File '{file_path}' not found.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def describe_data(self):\n",
    "        \"\"\"\n",
    "        Print the shape, column names, and basic statistics of the dataset.\n",
    "        Provides insights based on the statistics.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"DATASET OVERVIEW\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Shape\n",
    "        print(f\"\\nDataset Shape: {self.data.shape}\")\n",
    "        print(f\"   - Number of rows: {self.data.shape[0]:,}\")\n",
    "        print(f\"   - Number of columns: {self.data.shape[1]}\")\n",
    "        \n",
    "        # Column names and data types\n",
    "        print(f\"\\nColumn Names and Data Types:\")\n",
    "        print(\"-\" * 80)\n",
    "        for idx, (col, dtype) in enumerate(zip(self.data.columns, self.data.dtypes), 1):\n",
    "            print(f\"   {idx}. {col:<30} ({dtype})\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"\\nBasic Statistics (Numeric Columns):\")\n",
    "        print(\"-\" * 80)\n",
    "        print(self.data.describe())\n",
    "        \n",
    "        # Missing values\n",
    "        print(f\"\\nMissing Values:\")\n",
    "        print(\"-\" * 80)\n",
    "        missing = self.data.isnull().sum()\n",
    "        missing_pct = (missing / len(self.data) * 100).round(2)\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Missing Count': missing,\n",
    "            'Percentage': missing_pct\n",
    "        })\n",
    "        print(missing_df[missing_df['Missing Count'] > 0])\n",
    "        \n",
    "        # Data types summary\n",
    "        print(f\"\\nData Types Summary:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(self.data.dtypes.value_counts())\n",
    "        \n",
    "        # First few rows\n",
    "        print(f\"\\nFirst 5 Rows:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(self.data.head())\n",
    "        \n",
    "        # Enhanced Insights\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"COVID-19 DATA INSIGHTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        insights = []\n",
    "        \n",
    "        # 1. Dataset size and scope\n",
    "        insights.append(\"1. DATASET SCOPE:\")\n",
    "        insights.append(f\"   Large dataset with {self.data.shape[0]:,} records across {self.data.shape[1]} variables\")\n",
    "        \n",
    "        # 2. Geographic coverage\n",
    "        unique_countries = self.data['Country/Region'].nunique()\n",
    "        unique_regions = self.data['WHO Region'].nunique()\n",
    "        insights.append(f\"   Geographic coverage: {unique_countries} countries/territories across {unique_regions} WHO regions\")\n",
    "        \n",
    "        # 3. Temporal coverage\n",
    "        temp_date = pd.to_datetime(self.data['Date'], errors='coerce')\n",
    "        if not temp_date.isna().all():\n",
    "            date_min = temp_date.min()\n",
    "            date_max = temp_date.max()\n",
    "            date_range_days = (date_max - date_min).days\n",
    "            insights.append(f\"   Time period: {date_min.date()} to {date_max.date()} ({date_range_days} days)\")\n",
    "        \n",
    "        # 4. Data quality insights\n",
    "        insights.append(\"\\n2. DATA QUALITY:\")\n",
    "        total_missing = self.data.isnull().sum().sum()\n",
    "        if total_missing > 0:\n",
    "            missing_pct_total = (total_missing / (self.data.shape[0] * self.data.shape[1]) * 100).round(2)\n",
    "            insights.append(f\"   Missing data: {total_missing:,} values ({missing_pct_total}% of dataset)\")\n",
    "            insights.append(f\"   Primary gap: Province/State column (70.11% missing - expected for country-level data)\")\n",
    "        else:\n",
    "            insights.append(\"   No missing values detected\")\n",
    "        \n",
    "        # Check for data anomalies\n",
    "        if self.data['Active'].min() < 0:\n",
    "            insights.append(f\"   Data anomaly detected: Negative active cases (min: {self.data['Active'].min()})\")\n",
    "            insights.append(\"   This suggests data reporting inconsistencies that may need investigation\")\n",
    "        \n",
    "        # 5. Impact analysis - Top affected countries\n",
    "        insights.append(\"\\n3. GLOBAL IMPACT OVERVIEW:\")\n",
    "        \n",
    "        # Get latest data per country for accurate totals\n",
    "        latest_data = self.data.sort_values('Date').groupby('Country/Region').last()\n",
    "        \n",
    "        total_confirmed = self.data['Confirmed'].sum()\n",
    "        total_deaths = self.data['Deaths'].sum()\n",
    "        total_recovered = self.data['Recovered'].sum()\n",
    "        \n",
    "        insights.append(f\"   Total cumulative cases: {total_confirmed:,}\")\n",
    "        insights.append(f\"   Total deaths: {total_deaths:,}\")\n",
    "        insights.append(f\"   Total recovered: {total_recovered:,}\")\n",
    "        \n",
    "        if total_confirmed > 0:\n",
    "            global_cfr = (total_deaths / total_confirmed) * 100\n",
    "            insights.append(f\"   Global case fatality rate: {global_cfr:.2f}%\")\n",
    "        \n",
    "        # 6. Most affected countries\n",
    "        insights.append(\"\\n4. MOST AFFECTED COUNTRIES (by latest confirmed cases):\")\n",
    "        top_countries = latest_data.nlargest(5, 'Confirmed')[['Confirmed', 'Deaths', 'Recovered']]\n",
    "        for idx, (country, row) in enumerate(top_countries.iterrows(), 1):\n",
    "            cfr = (row['Deaths'] / row['Confirmed'] * 100) if row['Confirmed'] > 0 else 0\n",
    "            insights.append(f\"   {idx}. {country}: {row['Confirmed']:,} cases, {row['Deaths']:,} deaths (CFR: {cfr:.2f}%)\")\n",
    "        \n",
    "        # 7. WHO Regional distribution\n",
    "        insights.append(\"\\n5. WHO REGIONAL DISTRIBUTION:\")\n",
    "        regional_data = latest_data.groupby('WHO Region').agg({\n",
    "            'Confirmed': 'sum',\n",
    "            'Deaths': 'sum'\n",
    "        }).sort_values('Confirmed', ascending=False)\n",
    "        \n",
    "        for region, row in regional_data.iterrows():\n",
    "            pct_of_total = (row['Confirmed'] / latest_data['Confirmed'].sum() * 100)\n",
    "            insights.append(f\"   {region}: {row['Confirmed']:,} cases ({pct_of_total:.1f}% of global total)\")\n",
    "        \n",
    "        # 8. Data characteristics\n",
    "        insights.append(\"\\n6. STATISTICAL CHARACTERISTICS:\")\n",
    "        insights.append(f\"   Median confirmed cases per record: {self.data['Confirmed'].median():,.0f}\")\n",
    "        insights.append(f\"   High variance in data (std dev: {self.data['Confirmed'].std():,.0f}) indicates\")\n",
    "        insights.append(\"   wide disparity in outbreak severity across regions and time periods\")\n",
    "        \n",
    "        # Print all insights\n",
    "        for insight in insights:\n",
    "            print(insight)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    def handle_missing_values(self):\n",
    "        \"\"\"\n",
    "        Handle missing values in the dataset:\n",
    "        - Fill missing numeric values with 0\n",
    "        - Fill missing categorical values with \"Unknown\"\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"HANDLING MISSING VALUES\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Check for missing values before\n",
    "        missing_before = self.data.isnull().sum().sum()\n",
    "        print(f\"\\nMissing values before: {missing_before:,}\")\n",
    "        \n",
    "        if missing_before == 0:\n",
    "            print(\"\\nNo missing values found. Data is already complete!\")\n",
    "            return self.data\n",
    "        \n",
    "        # Identify numeric and categorical columns\n",
    "        numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_cols = self.data.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "        # Fill numeric columns with 0\n",
    "        if numeric_cols:\n",
    "            print(f\"\\nFilling {len(numeric_cols)} numeric columns with 0:\")\n",
    "            for col in numeric_cols:\n",
    "                missing_count = self.data[col].isnull().sum()\n",
    "                if missing_count > 0:\n",
    "                    self.data[col] = self.data[col].fillna(0)\n",
    "                    print(f\"   - {col}: filled {missing_count} missing values\")\n",
    "        \n",
    "        # Fill categorical columns with \"Unknown\"\n",
    "        if categorical_cols:\n",
    "            print(f\"\\nFilling {len(categorical_cols)} categorical columns with 'Unknown':\")\n",
    "            for col in categorical_cols:\n",
    "                missing_count = self.data[col].isnull().sum()\n",
    "                if missing_count > 0:\n",
    "                    self.data[col] = self.data[col].fillna(\"Unknown\")\n",
    "                    print(f\"   - {col}: filled {missing_count} missing values\")\n",
    "        \n",
    "        # Check for missing values after\n",
    "        missing_after = self.data.isnull().sum().sum()\n",
    "        print(f\"\\nMissing values after: {missing_after:,}\")\n",
    "        print(f\"Successfully handled {missing_before - missing_after:,} missing values!\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def filter_high_cases(self) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Filter the dataset based on multiple conditions:\n",
    "        - Confirmed cases greater than 100,000\n",
    "        - Deaths above 5,000\n",
    "        - Country is not \"Unknown\"\n",
    "        \n",
    "        Saves the filtered data to self.filtered_data\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"FILTERING HIGH CASES\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Apply filters\n",
    "        print(\"\\nApplying filters:\")\n",
    "        print(\"   - Confirmed cases > 100,000\")\n",
    "        print(\"   - Deaths > 5,000\")\n",
    "        print(\"   - Country/Region != 'Unknown'\")\n",
    "        \n",
    "        self.filtered_data = self.data[\n",
    "            (self.data['Confirmed'] > 100000) & \n",
    "            (self.data['Deaths'] > 5000) & \n",
    "            (self.data['Country/Region'] != 'Unknown')\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"   - Original dataset: {len(self.data):,} rows\")\n",
    "        print(f\"   - Filtered dataset: {len(self.filtered_data):,} rows\")\n",
    "        print(f\"   - Rows filtered out: {len(self.data) - len(self.filtered_data):,}\")\n",
    "        \n",
    "        if len(self.filtered_data) > 0:\n",
    "            print(f\"\\nFiltered data saved to self.filtered_data\")\n",
    "            print(\"\\nSummary of filtered data:\")\n",
    "            print(f\"   - Unique countries: {self.filtered_data['Country/Region'].nunique()}\")\n",
    "            print(f\"   - Total confirmed cases: {self.filtered_data['Confirmed'].sum():,}\")\n",
    "            print(f\"   - Total deaths: {self.filtered_data['Deaths'].sum():,}\")\n",
    "            print(f\"   - Average confirmed cases: {self.filtered_data['Confirmed'].mean():,.0f}\")\n",
    "            print(f\"   - Average deaths: {self.filtered_data['Deaths'].mean():,.0f}\")\n",
    "        else:\n",
    "            print(\"\\nNo records match the filter criteria.\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return self.filtered_data\n",
    "    \n",
    "    def filter_by_date_range(self, start_date, end_date) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Filter the dataset by a specified date range.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date (string like '2020-01-01' or datetime object)\n",
    "            end_date: End date (string like '2020-12-31' or datetime object)\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered dataframe within the date range\n",
    "            \n",
    "        Saves the filtered data to self.filtered_data\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return None\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"FILTERING BY DATE RANGE\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        try:\n",
    "            # Convert start_date and end_date to datetime\n",
    "            start_dt = pd.to_datetime(start_date)\n",
    "            end_dt = pd.to_datetime(end_date)\n",
    "            \n",
    "            print(f\"\\nDate range: {start_dt.date()} to {end_dt.date()}\")\n",
    "            \n",
    "            # Ensure Date column is in datetime format\n",
    "            if self.data['Date'].dtype == 'object':\n",
    "                print(\"Converting Date column to datetime format...\")\n",
    "                self.data['Date'] = pd.to_datetime(self.data['Date'])\n",
    "            \n",
    "            # Filter data by date range\n",
    "            self.filtered_data = self.data[\n",
    "                (self.data['Date'] >= start_dt) & \n",
    "                (self.data['Date'] <= end_dt)\n",
    "            ]\n",
    "            \n",
    "            print(f\"\\nResults:\")\n",
    "            print(f\"   - Original dataset: {len(self.data):,} rows\")\n",
    "            print(f\"   - Filtered dataset: {len(self.filtered_data):,} rows\")\n",
    "            print(f\"   - Rows filtered out: {len(self.data) - len(self.filtered_data):,}\")\n",
    "            \n",
    "            if len(self.filtered_data) > 0:\n",
    "                print(f\"\\nFiltered data saved to self.filtered_data\")\n",
    "                print(f\"\\nDate range in filtered data:\")\n",
    "                print(f\"   - Earliest date: {self.filtered_data['Date'].min().date()}\")\n",
    "                print(f\"   - Latest date: {self.filtered_data['Date'].max().date()}\")\n",
    "                print(f\"   - Total confirmed cases: {self.filtered_data['Confirmed'].sum():,}\")\n",
    "                print(f\"   - Total deaths: {self.filtered_data['Deaths'].sum():,}\")\n",
    "            else:\n",
    "                print(\"\\nNo records found within the specified date range.\")\n",
    "            \n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            return self.filtered_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError filtering by date range: {e}\")\n",
    "            print(\"Please ensure dates are in a valid format (e.g., '2020-01-01' or 'YYYY-MM-DD')\")\n",
    "            print(\"=\" * 80)\n",
    "            return None\n",
    "    \n",
    "    def calculate_global_statistics(self):\n",
    "        \"\"\"\n",
    "        Calculate global statistics for Confirmed, Deaths, and Recovered cases.\n",
    "        Uses numpy for calculations and prints the results.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"No data loaded. Please load data first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"GLOBAL STATISTICS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Use numpy to calculate totals\n",
    "        total_confirmed = np.sum(self.data['Confirmed'].values)\n",
    "        total_deaths = np.sum(self.data['Deaths'].values)\n",
    "        total_recovered = np.sum(self.data['Recovered'].values)\n",
    "        \n",
    "        print(f\"\\nGlobal Totals:\")\n",
    "        print(f\"   - Total Confirmed Cases: {total_confirmed:,}\")\n",
    "        print(f\"   - Total Deaths: {total_deaths:,}\")\n",
    "        print(f\"   - Total Recovered: {total_recovered:,}\")\n",
    "        \n",
    "        # Calculate additional statistics using numpy\n",
    "        print(f\"\\nAdditional Statistics:\")\n",
    "        \n",
    "        # Death rate\n",
    "        if total_confirmed > 0:\n",
    "            death_rate = (total_deaths / total_confirmed) * 100\n",
    "            print(f\"   - Global Death Rate: {death_rate:.2f}%\")\n",
    "        \n",
    "        # Recovery rate\n",
    "        if total_confirmed > 0:\n",
    "            recovery_rate = (total_recovered / total_confirmed) * 100\n",
    "            print(f\"   - Global Recovery Rate: {recovery_rate:.2f}%\")\n",
    "        \n",
    "        # Average cases per record using numpy\n",
    "        avg_confirmed = np.mean(self.data['Confirmed'].values)\n",
    "        avg_deaths = np.mean(self.data['Deaths'].values)\n",
    "        avg_recovered = np.mean(self.data['Recovered'].values)\n",
    "        \n",
    "        print(f\"\\nAverage per Record:\")\n",
    "        print(f\"   - Average Confirmed: {avg_confirmed:,.2f}\")\n",
    "        print(f\"   - Average Deaths: {avg_deaths:,.2f}\")\n",
    "        print(f\"   - Average Recovered: {avg_recovered:,.2f}\")\n",
    "        \n",
    "        # Standard deviation using numpy\n",
    "        std_confirmed = np.std(self.data['Confirmed'].values)\n",
    "        std_deaths = np.std(self.data['Deaths'].values)\n",
    "        std_recovered = np.std(self.data['Recovered'].values)\n",
    "        \n",
    "        print(f\"\\nStandard Deviation:\")\n",
    "        print(f\"   - Confirmed: {std_confirmed:,.2f}\")\n",
    "        print(f\"   - Deaths: {std_deaths:,.2f}\")\n",
    "        print(f\"   - Recovered: {std_recovered:,.2f}\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    def save_filtered_data(self, filename):\n",
    "        \"\"\"\n",
    "        Save the filtered data to a CSV file.\n",
    "        \n",
    "        Args:\n",
    "            filename (str): Name of the CSV file to save (e.g., 'filtered_data.csv')\n",
    "        \"\"\"\n",
    "        if self.filtered_data is None:\n",
    "            print(\"No filtered data available. Please filter data first.\")\n",
    "            return\n",
    "        \n",
    "        if len(self.filtered_data) == 0:\n",
    "            print(\"Filtered data is empty. Nothing to save.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"SAVING FILTERED DATA\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        try:\n",
    "            # Save filtered data to CSV\n",
    "            self.filtered_data.to_csv(filename, index=False)\n",
    "            \n",
    "            print(f\"\\nFiltered data saved successfully!\")\n",
    "            print(f\"   - Filename: {filename}\")\n",
    "            print(f\"   - Rows saved: {len(self.filtered_data):,}\")\n",
    "            print(f\"   - Columns saved: {len(self.filtered_data.columns)}\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError saving filtered data: {e}\")\n",
    "            print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Data Analyzer\n",
    "\n",
    "Below is an example of how to use the CovidDataAnalyzer class with sample output:\n",
    "\n",
    "**Expected Output:**\n",
    "- Data loading confirmation with dataset shape\n",
    "- Dataset overview with statistics and insights\n",
    "- Missing values handling report\n",
    "- Filtered data results with summary statistics\n",
    "- Preview of the first 5 filtered records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T19:05:07.166450Z",
     "iopub.status.busy": "2025-11-11T19:05:07.166450Z",
     "iopub.status.idle": "2025-11-11T19:05:07.280062Z",
     "shell.execute_reply": "2025-11-11T19:05:07.280062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from covid_19_data.csv\n",
      "Dataset shape: (49068, 10)\n",
      "================================================================================\n",
      "DATASET OVERVIEW\n",
      "================================================================================\n",
      "\n",
      "Dataset Shape: (49068, 10)\n",
      "   - Number of rows: 49,068\n",
      "   - Number of columns: 10\n",
      "\n",
      "Column Names and Data Types:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. Province/State                 (object)\n",
      "   2. Country/Region                 (object)\n",
      "   3. Lat                            (float64)\n",
      "   4. Long                           (float64)\n",
      "   5. Date                           (object)\n",
      "   6. Confirmed                      (int64)\n",
      "   7. Deaths                         (int64)\n",
      "   8. Recovered                      (int64)\n",
      "   9. Active                         (int64)\n",
      "   10. WHO Region                     (object)\n",
      "\n",
      "Basic Statistics (Numeric Columns):\n",
      "--------------------------------------------------------------------------------\n",
      "                Lat          Long     Confirmed         Deaths     Recovered  \\\n",
      "count  49068.000000  49068.000000  4.906800e+04   49068.000000  4.906800e+04   \n",
      "mean      21.433730     23.528236  1.688490e+04     884.179160  7.915713e+03   \n",
      "std       24.950320     70.442740  1.273002e+05    6313.584411  5.480092e+04   \n",
      "min      -51.796300   -135.000000  0.000000e+00       0.000000  0.000000e+00   \n",
      "25%        7.873054    -15.310100  4.000000e+00       0.000000  0.000000e+00   \n",
      "50%       23.634500     21.745300  1.680000e+02       2.000000  2.900000e+01   \n",
      "75%       41.204380     80.771797  1.518250e+03      30.000000  6.660000e+02   \n",
      "max       71.706900    178.065000  4.290259e+06  148011.000000  1.846641e+06   \n",
      "\n",
      "             Active  \n",
      "count  4.906800e+04  \n",
      "mean   8.085012e+03  \n",
      "std    7.625890e+04  \n",
      "min   -1.400000e+01  \n",
      "25%    0.000000e+00  \n",
      "50%    2.600000e+01  \n",
      "75%    6.060000e+02  \n",
      "max    2.816444e+06  \n",
      "\n",
      "Missing Values:\n",
      "--------------------------------------------------------------------------------\n",
      "                Missing Count  Percentage\n",
      "Province/State          34404       70.11\n",
      "\n",
      "Data Types Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "object     4\n",
      "int64      4\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 Rows:\n",
      "--------------------------------------------------------------------------------\n",
      "  Province/State Country/Region       Lat       Long        Date  Confirmed  \\\n",
      "0            NaN    Afghanistan  33.93911  67.709953  2020-01-22          0   \n",
      "1            NaN        Albania  41.15330  20.168300  2020-01-22          0   \n",
      "2            NaN        Algeria  28.03390   1.659600  2020-01-22          0   \n",
      "3            NaN        Andorra  42.50630   1.521800  2020-01-22          0   \n",
      "4            NaN         Angola -11.20270  17.873900  2020-01-22          0   \n",
      "\n",
      "   Deaths  Recovered  Active             WHO Region  \n",
      "0       0          0       0  Eastern Mediterranean  \n",
      "1       0          0       0                 Europe  \n",
      "2       0          0       0                 Africa  \n",
      "3       0          0       0                 Europe  \n",
      "4       0          0       0                 Africa  \n",
      "\n",
      "================================================================================\n",
      "COVID-19 DATA INSIGHTS\n",
      "================================================================================\n",
      "1. DATASET SCOPE:\n",
      "   Large dataset with 49,068 records across 10 variables\n",
      "   Geographic coverage: 187 countries/territories across 6 WHO regions\n",
      "   Time period: 2020-01-22 to 2020-07-27 (187 days)\n",
      "\n",
      "2. DATA QUALITY:\n",
      "   Missing data: 34,404 values (7.01% of dataset)\n",
      "   Primary gap: Province/State column (70.11% missing - expected for country-level data)\n",
      "   Data anomaly detected: Negative active cases (min: -14)\n",
      "   This suggests data reporting inconsistencies that may need investigation\n",
      "\n",
      "3. GLOBAL IMPACT OVERVIEW:\n",
      "   Total cumulative cases: 828,508,482\n",
      "   Total deaths: 43,384,903\n",
      "   Total recovered: 388,408,229\n",
      "   Global case fatality rate: 5.24%\n",
      "\n",
      "4. MOST AFFECTED COUNTRIES (by latest confirmed cases):\n",
      "   1. US: 4,290,259 cases, 148,011 deaths (CFR: 3.45%)\n",
      "   2. Brazil: 2,442,375 cases, 87,618 deaths (CFR: 3.59%)\n",
      "   3. India: 1,480,073 cases, 33,408 deaths (CFR: 2.26%)\n",
      "   4. Russia: 816,680 cases, 13,334 deaths (CFR: 1.63%)\n",
      "   5. South Africa: 452,529 cases, 7,067 deaths (CFR: 1.56%)\n",
      "\n",
      "5. WHO REGIONAL DISTRIBUTION:\n",
      "   Americas: 8,724,037 cases (53.9% of global total)\n",
      "   Europe: 3,232,731 cases (20.0% of global total)\n",
      "   South-East Asia: 1,835,297 cases (11.3% of global total)\n",
      "   Eastern Mediterranean: 1,490,744 cases (9.2% of global total)\n",
      "   Africa: 723,207 cases (4.5% of global total)\n",
      "   Western Pacific: 192,271 cases (1.2% of global total)\n",
      "\n",
      "6. STATISTICAL CHARACTERISTICS:\n",
      "   Median confirmed cases per record: 168\n",
      "   High variance in data (std dev: 127,300) indicates\n",
      "   wide disparity in outbreak severity across regions and time periods\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "HANDLING MISSING VALUES\n",
      "================================================================================\n",
      "\n",
      "Missing values before: 34,404\n",
      "\n",
      "Filling 6 numeric columns with 0:\n",
      "\n",
      "Filling 4 categorical columns with 'Unknown':\n",
      "   - Province/State: filled 34404 missing values\n",
      "\n",
      "Missing values after: 0\n",
      "Successfully handled 34,404 missing values!\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FILTERING HIGH CASES\n",
      "================================================================================\n",
      "\n",
      "Applying filters:\n",
      "   - Confirmed cases > 100,000\n",
      "   - Deaths > 5,000\n",
      "   - Country/Region != 'Unknown'\n",
      "\n",
      "Results:\n",
      "   - Original dataset: 49,068 rows\n",
      "   - Filtered dataset: 1,172 rows\n",
      "   - Rows filtered out: 47,896\n",
      "\n",
      "Filtered data saved to self.filtered_data\n",
      "\n",
      "Summary of filtered data:\n",
      "   - Unique countries: 17\n",
      "   - Total confirmed cases: 574,104,344\n",
      "   - Total deaths: 34,157,472\n",
      "   - Average confirmed cases: 489,850\n",
      "   - Average deaths: 29,145\n",
      "================================================================================\n",
      "      Province/State Country/Region        Lat       Long        Date  \\\n",
      "17883        Unknown          Italy  41.871940   12.56738  2020-03-30   \n",
      "18144        Unknown          Italy  41.871940   12.56738  2020-03-31   \n",
      "18232        Unknown             US  40.000000 -100.00000  2020-03-31   \n",
      "18405        Unknown          Italy  41.871940   12.56738  2020-04-01   \n",
      "18469        Unknown          Spain  40.463667   -3.74922  2020-04-01   \n",
      "\n",
      "       Confirmed  Deaths  Recovered  Active WHO Region  \n",
      "17883     101739   11591      14620   75528     Europe  \n",
      "18144     105792   12428      15729   77635     Europe  \n",
      "18232     188724    5605       7024  176095   Americas  \n",
      "18405     110574   13155      16847   80572     Europe  \n",
      "18469     104118    9387      22647   72084     Europe  \n",
      "================================================================================\n",
      "SAVING FILTERED DATA\n",
      "================================================================================\n",
      "\n",
      "Filtered data saved successfully!\n",
      "   - Filename: filtered_high_cases.csv\n",
      "   - Rows saved: 1,172\n",
      "   - Columns saved: 10\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FILTERING BY DATE RANGE\n",
      "================================================================================\n",
      "\n",
      "Date range: 2020-03-01 to 2020-06-30\n",
      "Converting Date column to datetime format...\n",
      "\n",
      "Results:\n",
      "   - Original dataset: 49,068 rows\n",
      "   - Filtered dataset: 31,842 rows\n",
      "   - Rows filtered out: 17,226\n",
      "\n",
      "Filtered data saved to self.filtered_data\n",
      "\n",
      "Date range in filtered data:\n",
      "   - Earliest date: 2020-03-01\n",
      "   - Latest date: 2020-06-30\n",
      "   - Total confirmed cases: 463,910,663\n",
      "   - Total deaths: 27,627,472\n",
      "================================================================================\n",
      "      Province/State Country/Region       Lat       Long       Date  \\\n",
      "10179        Unknown    Afghanistan  33.93911  67.709953 2020-03-01   \n",
      "10180        Unknown        Albania  41.15330  20.168300 2020-03-01   \n",
      "10181        Unknown        Algeria  28.03390   1.659600 2020-03-01   \n",
      "10182        Unknown        Andorra  42.50630   1.521800 2020-03-01   \n",
      "10183        Unknown         Angola -11.20270  17.873900 2020-03-01   \n",
      "\n",
      "       Confirmed  Deaths  Recovered  Active             WHO Region  \n",
      "10179          1       0          0       1  Eastern Mediterranean  \n",
      "10180          0       0          0       0                 Europe  \n",
      "10181          1       0          0       1                 Africa  \n",
      "10182          0       0          0       0                 Europe  \n",
      "10183          0       0          0       0                 Africa  \n",
      "================================================================================\n",
      "SAVING FILTERED DATA\n",
      "================================================================================\n",
      "\n",
      "Filtered data saved successfully!\n",
      "   - Filename: filtered_march_to_june_2020.csv\n",
      "   - Rows saved: 31,842\n",
      "   - Columns saved: 10\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GLOBAL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Global Totals:\n",
      "   - Total Confirmed Cases: 828,508,482\n",
      "   - Total Deaths: 43,384,903\n",
      "   - Total Recovered: 388,408,229\n",
      "\n",
      "Additional Statistics:\n",
      "   - Global Death Rate: 5.24%\n",
      "   - Global Recovery Rate: 46.88%\n",
      "\n",
      "Average per Record:\n",
      "   - Average Confirmed: 16,884.90\n",
      "   - Average Deaths: 884.18\n",
      "   - Average Recovered: 7,915.71\n",
      "\n",
      "Standard Deviation:\n",
      "   - Confirmed: 127,298.91\n",
      "   - Deaths: 6,313.52\n",
      "   - Recovered: 54,800.36\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example usage - Part 3: Putting It All Together\n",
    "analyzer = CovidDataAnalyzer('covid_19_data.csv')\n",
    "\n",
    "# Step 2: Load and describe the dataset\n",
    "analyzer.describe_data()\n",
    "\n",
    "# Step 3: Handle missing values\n",
    "analyzer.handle_missing_values()\n",
    "\n",
    "# Step 4: Apply filter_high_cases and save the filtered data\n",
    "print(\"\\n\")\n",
    "analyzer.filter_high_cases()\n",
    "print(analyzer.filtered_data.head())\n",
    "analyzer.save_filtered_data('filtered_high_cases.csv')\n",
    "\n",
    "# Step 5: Apply filter_by_date_range (March 2020 to June 2020) and save\n",
    "print(\"\\n\")\n",
    "analyzer.filter_by_date_range('2020-03-01', '2020-06-30')\n",
    "print(analyzer.filtered_data.head())\n",
    "analyzer.save_filtered_data('filtered_march_to_june_2020.csv')\n",
    "\n",
    "# Step 6: Calculate and display global statistics\n",
    "print(\"\\n\")\n",
    "analyzer.calculate_global_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
